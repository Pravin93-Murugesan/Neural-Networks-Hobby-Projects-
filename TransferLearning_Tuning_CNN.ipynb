{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 1. Pre-trained neural networks"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Researchers have built accurate image recognition systems. So instead of training our own neural network from scratch, we could reuse an existing neural network design as a starting point in projects. Some popular neural network designs that we can reuse:\n\n- **VGG** is a deep network with either 16 or 19 layers, *University of Oxford* (2014) \n- **ResNet-50** is a 50 layer neural network, *Microsoft* (2015)\n- **Inception v3** is another design, *Google* (2015) \n\nThese pre-trained neural networks are included with Keras. The models are all trained to recognize images from the ImageNet data set."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nfrom keras.preprocessing import image\nfrom keras.applications import vgg16",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using TensorFlow backend.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Load Keras' VGG16 model that was pre-trained against the ImageNet database\nmodel = vgg16.VGG16()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Load the image file, resizing it to 224x224 pixels (required by this model)\nimg = image.load_img(\"bay.jpg\", target_size=(224, 224))\n\n# Convert the image to a numpy array\nx = image.img_to_array(img)\n\n# Add a fourth dimension (since Keras expects a list of images)\nx = np.expand_dims(x, axis=0)\n\n# Normalize the input image's pixel values to the range used when training the neural network\nx = vgg16.preprocess_input(x)\n\n# Run the image through the deep neural network to make a prediction\npredictions = model.predict(x)\n\n# Look up the names of the predicted classes. Index zero is the results for the first image.\npredicted_classes = vgg16.decode_predictions(predictions)\n\nprint(\"Top predictions for this image:\")\n\nfor imagenet_id, name, likelihood in predicted_classes[0]:\n    print(\"Prediction: {} - {:2f}\".format(name, likelihood))",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Top predictions for this image:\nPrediction: seashore - 0.395213\nPrediction: promontory - 0.326128\nPrediction: lakeside - 0.119613\nPrediction: breakwater - 0.062801\nPrediction: sandbar - 0.045267\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 2. Transfer learning (another alternative to training a new neural network)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "In reality, you almost never need to train the neural network from scratch. Instead, we can use transfer learning to reuse an existing neural network and adapt it to a new problem. Transfer learning is where you take a model trained on one set of data and then use the knowledge it learned to give it a headstart when solving a new problem.\n\nThe basic idea is that neural networks learn to detect simple patterns in the top layer, and then the next layer uses that information to look for slightly more complex patterns and so on, down through all the convolutional layers. But the final layer of the neural network is a densely connected layer that uses the information from the convolutional layers to decide which object is in the image. \n\nWith transfer learning, we start with a neural network that's already been trained to recognize objects from a large dataset. To reuse this neural network with new data, we can simply slice off the last layer. We will keep all the layers that detect patterns, but remove the part that maps those patterns to specific objects and ``call this pre-trained neural network a feature extractor`` because we're using it to extract training features from images. Then, we create a new neural network to replace the last layer in the original network. This is the only part that we will have to train ourselves. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from pathlib import Path\nimport numpy as np\nimport joblib",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Feature extraction"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Path to folders with training data\ndog_path = Path(\"training_data\") / \"dogs2\"\nnot_dog_path = Path(\"training_data\") / \"not_dogs2\"\n\nimages = []\nlabels = []\n\n# Load all the not-dog images\nfor img in not_dog_path.glob(\"*.png\"):\n    # Load the image from disk\n    img = image.load_img(img)\n\n    # Convert the image to a numpy array\n    image_array = image.img_to_array(img)\n\n    # Add the image to the list of images\n    images.append(image_array)\n\n    # For each 'not dog' image, the expected value should be 0\n    labels.append(0)\n\n# Load all the dog images\nfor img in dog_path.glob(\"*.png\"):\n    # Load the image from disk\n    img = image.load_img(img)\n\n    # Convert the image to a numpy array\n    image_array = image.img_to_array(img)\n\n    # Add the image to the list of images\n    images.append(image_array)\n\n    # For each 'dog' image, the expected value should be 1\n    labels.append(1)\n\n# Create a single numpy array with all the images we loaded\nx_train = np.array(images)\n\n# Also convert the labels to a numpy array\ny_train = np.array(labels)\n\n# Normalize image data to 0-to-1 range\nx_train = vgg16.preprocess_input(x_train)\n\n# Load a pre-trained neural network to use as a feature extractor\npretrained_nn = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n\n# Extract features for each image (all in one pass)\nfeatures_x = pretrained_nn.predict(x_train)\n\n# Save the array of extracted features to a file\njoblib.dump(features_x, \"x_train.dat\")\n\n# Save the matching array of expected values to a file\njoblib.dump(y_train, \"y_train.dat\")",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58892288/58889256 [==============================] - 10s 0us/step\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "['y_train.dat']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "### Training with extracted features"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Load data set\nx_train = joblib.load(\"x_train.dat\")\ny_train = joblib.load(\"y_train.dat\")\n\n# Create a model and add layers\nmodel = Sequential()\n\nmodel.add(Flatten(input_shape=x_train.shape[1:]))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compile the model\nmodel.compile(\n    loss=\"binary_crossentropy\",\n    optimizer=\"adam\",\n    metrics=['accuracy']\n)\n\n# Train the model\nmodel.fit(\n    x_train,\n    y_train,\n    epochs=10,\n    shuffle=True\n)\n\n# Save neural network structure\nmodel_structure = model.to_json()\nf = Path(\"model_structure.json\")\nf.write_text(model_structure)\n\n# Save neural network's trained weights\nmodel.save_weights(\"model_weights.h5\")",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "WARNING:tensorflow:From /home/nbuser/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:182: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\nEpoch 1/10\n58/58 [==============================] - 1s 11ms/step - loss: 15.7117 - accuracy: 0.4483\nEpoch 2/10\n58/58 [==============================] - 0s 256us/step - loss: 1.9552 - accuracy: 0.8621\nEpoch 3/10\n58/58 [==============================] - 0s 205us/step - loss: 0.2158 - accuracy: 0.9655\nEpoch 4/10\n58/58 [==============================] - 0s 189us/step - loss: 0.1633 - accuracy: 0.9828\nEpoch 5/10\n58/58 [==============================] - 0s 190us/step - loss: 0.0268 - accuracy: 0.9828\nEpoch 6/10\n58/58 [==============================] - 0s 208us/step - loss: 0.0399 - accuracy: 0.9828\nEpoch 7/10\n58/58 [==============================] - 0s 199us/step - loss: 4.7841e-10 - accuracy: 1.0000\nEpoch 8/10\n58/58 [==============================] - 0s 269us/step - loss: 6.3526e-08 - accuracy: 1.0000\nEpoch 9/10\n58/58 [==============================] - 0s 188us/step - loss: 3.0882e-13 - accuracy: 1.0000\nEpoch 10/10\n58/58 [==============================] - 0s 271us/step - loss: 3.7069e-04 - accuracy: 1.0000\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Note that it took ``so little time to train`` the model."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Making predictions"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.models import model_from_json",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Load the json file that contains the model's structure\nf = Path(\"model_structure.json\")\nmodel_structure = f.read_text()\n\n# Recreate the Keras model object from the json data\nmodel = model_from_json(model_structure)\n\n# Re-load the model's trained weights\nmodel.load_weights(\"model_weights.h5\")\n\n# Testing with two images\nIMGS = [\"dog.png\", \"not_dog.png\"]\nfor c in IMGS:\n    # Load an image file to test, resizing it to 64x64 pixels (as required by this model)\n    img = image.load_img(c, target_size=(64, 64))\n\n    # Convert the image to a numpy array\n    image_array = image.img_to_array(img)\n\n    # Add a forth dimension to the image (since Keras expects a bunch of images, not a single image)\n    images = np.expand_dims(image_array, axis=0)\n\n    # Normalize the data\n    images = vgg16.preprocess_input(images)\n\n    # Use the pre-trained neural network to extract features from our test image (the same way we did to train the model)\n    feature_extraction_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n    features = feature_extraction_model.predict(images)\n\n    # Given the extracted features, make a final prediction using our own model\n    results = model.predict(features)\n\n    # Since we are only testing one image with possible class, we only need to check the first result's first element\n    single_result = results[0][0]\n\n    # Print the result\n    print(\"Likelihood that this image contains a dog: {} %\".format(int(single_result * 100)))",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Likelihood that this image contains a dog: 100 %\nLikelihood that this image contains a dog: 0 %\n",
          "name": "stdout"
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}